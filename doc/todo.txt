put @Override on everything

index: "suggested tokens" - suggest what other people should tag this index as;
       they are free to ignore this suggestion


- TODO - find a data structure other than SortedSet to store the tokens in.
- it must be able to sort by relevance, but have same-relevance items in as long as they don't equals().
- there should be only one entry per URI per Token (enforce this in the code at some point)


- TODO make TokenEntries immutable, and make Yaml stuff to create/uncreate these...

- URGENT for now, make URIKey use pkHash + docName for SSKs (until we find something better)


- PRIORITY merge URIWrapper with TokenURIEntry

- PRIORITY do we want to merge the library/ and index/ subpackages? or shuffle
things around?


- PRIORITY make a CompoundRequest that extends CompoundProgress (and make CompondProgress better and more standard)
- and it will have "getSubRequests" should go

- how to implement getSubStage* in Search, and how to put it back into
FindRequest
- implement nice version of finalTotalEstimate() in FindRequest and Search



------------



- TODO probably should synchronize AtomicProgress, SimpleProgress, and
  CompoundProgress... although maybe unnecessary since these should all be
  single-writer multi-reader (and the reads are not critical)?


- TODO work out TaskAbortException handling for SkeletonTreeMap
- TODO maybe have deflate/inflate throw a different checked exception from
  TaskAbortException, forcing them to handle the TaskAbortException thrown by
  pull/push?



- TODO setSerialiser only when data structure isLive()
- TODO use markdown-doclet instead of bliki-doclet
  - not yet - MarkdownJ has bugs relating to parsing of uppercase HTML tags,
    which SJD generates, unfortunately :/
- TODO make build.xml output test results better... atm either it has two modes:
  - print test stdout output out in real time, but not stderr
  - print stdout and stderr in a single go after the test is over :/


- TODO restructure the Serialiser.* stuff



>>> 7f0a7773dc3d60759145e10b750e706c584d8a7c
>>>
>>> URIKey: - I believe we agreed to index by the concatenation of the
>>> routing key and the uri hash? is that the current plan? you could index
>>> by the uri (toString(false, true) -> ascii), but that wouldn't be fixed
>>> length. i dunno how much locality of reference matters within a given
>>> routing key, if it does you need to either index by the actual uri or
>>> use a locality-preserving hash such as tea hash.
>> i'll need to rethink this at some point. the problem with just
>> concatenation is that you'll end up with a tree that's (length of the
>> first part) deep, with nodes in between that only have 1 children. so atm
>> i've gone with only routingKey (probably will soon change this to
>> routingKey + docName, as SSK uses). it will index small-to-medium sites
>> fine, but will be bad for extremely large (thousands of pages) sites.
>> maybe i could use skip-lists instead of a tree within a tree
>> (http://en.wikipedia.org/wiki/Skip_list).
>
> Maybe, I'm not sure how you'd lazily load a skiplist? I guess you can
> segment each level.
>
> Alternatively, what about allowing a child with a prefix longer than [ my
> prefix ] + 1, provided that all keys in that bucket (with that next-element)
> fit within it? And if and when one is added, create an intermediate subtree?
> Of course this means changing the parent pointer when you move the tree
> downwards, but is that such a big deal? You could have a protected or
> package-local accessor...

it would be easier to just grab a B-tree implementation and modify it to suit
our purposes, lol (and we wouldn't have to hash them into Tokens)... actually i
might do just that instead of coding a custom algorithm. atm though i'm going
to carry on other parts of the project, i can mess about with fine-tuning the
data structure more after the rest is working.




TODO refactor this, maybe..?
- have a Skeleton<K> interface with deflate(K) methods so that
SkeletonMap<K, V> extends Skeleton<K>



== Schedule ==

 - Packer for BTreeMap root 1-2 days
 - URI map, 2-3 days

 - implement freenet inflate/deflate 3-4 days
 - implement filters 2 days

 - implement fcp (mikeb is doing this part, he seems to be on top of it)

 - build interdex skeleton 3-4 days
 - implement interdex algorithm 5-7 days


 - implement WriteableIndex and commit algorithms 4-6 days
 - implement crawler...





