= Index =

== TODO ==

- can have terms containing spaces by eg. having crawler add "x y" to its dictionary of
terms to index, if it encounters this combination more than a few times on multiple pages.

- notes for synchronization:

read operations should be able to occur concurrently

put/remove modify the map structurally.
when this is happening, no other operations can happen

deflate/inflate modify the map data but not structure.
deflate/inflate should be able to occur concurrently on different nodes/keys
it should block put/remove operations, but not read operations


=== Index commit algorithm ===

have a "modCount" for each node. merge/split/rotate & put/remove update this

WriteableIndex keeps a "node -> modCount" map
at each commit, push all nodes that have a different modCount,
and update the map.

==== BTreeMap bulk-merge algorithm ====

node.putAll(SortedSet<K> set, Node parent):

	assert(node.lkey < set.first && set.last < node.rkey)

	if this is leaf:
		merge set with this node

	else:
		for n in subnodes:
			if n.lkey in set: update its value

			subset = { K in set: n.lkey < K < n.rkey }
			if subset is empty: continue
			n.putAll(subset, node)

	if size > node_max and parent != null:
		split this node up to respect the B-tree constraints
		attach the split nodes to the parent

tree.putAll(SortedSet<K> set):

	root.putAll(set, null)

	while root.size > node_max:
		create a new root
		split old root
		attach these to new root

==== Parallel BTreeMap bulk-merge algorithm ====

Closure<Node> inflate_subnodes(Node parent, SortedSet set):

	invoke(Node node):

		assert(node.lkey < set.first && set.last < node.rkey)

		if node is leaf:
			merge set with this node
			(new split(parent)).invoke(node)

		else:
			wait_map.put(node, node_waiters = {})

			for n in subnodes:
				if n.lkey in set: callback(k, v)

				subset = { K in set: n.lkey < K < n.rkey }
				if subset is empty: continue
				pull_queue.push(n)
				inflate_closures.put(n, new inflate_subnodes(node, subset))
				node_waiters.put(n)

			split_closures.put(node, new split(parent))

Closure<Node> split(Node parent):

	invoke(Node node):

		if size > node_max and parent != null:
			split this node up to respect the B-tree constraints
			attach split_nodes to the parent
		else:
			split_nodes = [this]

		node_waiters = wait_map.get(node)

		for n in split_nodes:
			push_queue.push(n)
			node_waiters.put(n)

		if node not in split_nodes:
			node_waiters.remove(node)

life cycle of a node:

- node gets popped from inflated
- enter inflate_subnodes
  - subnodes get pushed into pull_queue
  - (recurse for each subnode)
    - subnodes get popped from inflated
    - etc
    - subnodes get pushed into push_queue
- wait for all:
  - subnodes get popped from deflated
- enter split
  - split_nodes gets pushed into push_queue (needs exception for the root node)

!!! PriorityQueues must produce nodes in depth-first order !!!

execute(SortedSet<K> set):

	PriorityBlockingQueue inflated // output queue for pull-scheduler
	PriorityBlockingQueue pull_queue // input queue for pull-scheduler

	PriorityBlockingQueue deflated // output queue for push-scheduler
	PriorityBlockingQueue push_queue // input queue for push-scheduler

	IdentityHashMap<Node, [Node]> wait_map // wait queue for split_nodes

	IDMap<Node, Closure<Node>> inflate_closures
	IDMap<Node, Closure<Node>> split_closures

	inflated.push([root, null, set])

	do:

		while inflated not empty:
			node = inflated.pop()

			inflate_closures.remove(ghost_node).invoke(node)
			// FIXME get ghost_node from node

		while deflated not empty:
			node = deflated.pop()

			// FIXME get parent from node
			node_waiters = wait_map.get(parent)
			node_waiters.remove(node)
			assert(something was removed)

			if node_waiters.isEmpty():
				split_closures.remove(parent).invoke(parent)

	while (inflated + deflated + inflate_closures + split_closures) not empty


== Functionality ==

TODO sort this out

FetchTokenEntries [term]
ClearTokenEntries [term]

InsertTermEntry [data]
RemoveTermEntry [data]

FetchURIEntry [uri]
ClearURIEntry [uri]

InsertURIEntry [data]
RemoveURIEntry [data]

PullIndex [index]
PushIndex [index]






== Data elements ==

A "term" is a discrete phrase that results are associated with. This is just a
Java String, and can contain any character including whitespace.

A TermEntry stores data about a particular result for a term. Each entry has a
subject term and a relevance rating in [0,1]. Further types are:

 : TermTermEntry - redirects to another search term
 : TermIndexEntry - redirects to another index
 : TermPageEntry - final target for term

A URIKey is the node routing-key part of a FreenetURI and is used as the key
into the URI table. FreenetURIs from the same "site" will have the same URIKey
and will be stored close together in the table. (TODO: this might not be
necessary, especially if we use B+-trees instead of B-trees.)

A URIEntry stores data about a particular FreenetURI. Each entry has a quality
rating in [0,1]. Further types are:
 : etc? TODO

=== Unimplemented features ===

At the time of writing, there is no support for terms containing whitespace in
either XMLSpider or the syntax of the queries in the end-user interface.

There is also no support for URIEntrys in the spider or the interface.

== Data structure ==

 |-- contains
 :   subclass of

Index
 |-- metadata
 |-- ttab: BTreeMap<String, BTreeSet<TermEntry>>
 |-- utab: BTreeMap<URIKey, BTreeMap<FreenetURI, URIEntry>>

The index root would usually be stored as an SSK splitfile.

Conceptually, the ttab (term table) structure maps a term to (the collection of
entries for that term), and the utab (URI table) maps a FreenetURI to a single
unique URIEntry.

Structurally, both the ttab and utab are doubly-nested B-trees. There is a top
level B-tree, which maps a key to a further B-tree, which in turn holds data.

For the ttab, the top level B-tree maps a term to its entries collection, which
is a B-tree and can be nagivated. For the utab, the top level B-tree maps a
URIKey to a lower level B-tree that maps a FreenetURI to its URIEntry.


DOCUMENT usage of Bins


== Filters ==

TODO implement filters, think about how to do this...


