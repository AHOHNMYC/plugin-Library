= Index =

== TODO ==

- can have terms containing spaces by eg. having crawler add "x y" to its dictionary of
terms to index, if it encounters this combination more than a few times on multiple pages.

- notes for synchronization:

read operations should be able to occur concurrently

put/remove modify the map structurally.
when this is happening, no other operations can happen

deflate/inflate modify the map data but not structure.
deflate/inflate should be able to occur concurrently on different nodes/keys
it should block put/remove operations, but not read operations


=== Index commit algorithm ===

have a "modCount" for each node. merge/split/rotate & put/remove update this

WriteableIndex keeps a "node -> modCount" map
at each commit, push all nodes that have a different modCount,
and update the map.

==== BTreeMap bulk-merge algorithm ====

node.putAll(SortedSet<K> set, Node parent):

	assert(node.lkey < set.first && set.last < node.rkey)

	if this is leaf:
		merge set with this node

	else:
		for n in subnodes:
			if n.lkey in set: update its value

			subset = { K in set: n.lkey < K < n.rkey }
			if subset is empty: continue
			n.putAll(subset, node)

	if size > node_max and parent != null:
		split this node up to respect the B-tree constraints
		attach the split nodes to the parent

tree.putAll(SortedSet<K> set):

	root.putAll(set, null)

	while root.size > node_max:
		create a new root
		split old root
		attach these to new root

==== Parallel BTreeMap bulk-merge algorithm ====

handle_node(Node node, SortedSet set, PriorityQueue pull_queue):

	assert(node.lkey < set.first && set.last < node.rkey)

	if node is leaf:
		merge set with this node

	else:
		for n in subnodes:
			if n.lkey in set: callback(k, v)

			subset = { K in set: n.lkey < K < n.rkey }
			if subset is empty: continue
			pull_queue.push((n, node, subset))


split_node(Node node, Node parent):

	if size > node_max and parent != null:
		split this node up to respect the B-tree constraints
		attach the split_nodes to the parent

		for n in split_nodes:
			push_queue.push((n, parent))


execute(SortedSet<K> set):

	PriorityBlockingQueue inflated // output queue for pull-scheduler
	PriorityBlockingQueue pull_queue // input queue for pull-scheduler

	PriorityQueue handled

	PriorityBlockingQueue deflated // output queue for push-scheduler
	PriorityBlockingQueue push_queue // input queue for push-scheduler

	inflated.push([root, null, set])

	while job not done:

		while inflated not empty:
			(node, parent, subset) = inflated.pop()
			handle_node(node, parent, subset)

		while deflated not empty:
			(node, parent) = deflated.pop()

			if all subnodes of parent have been popped:
				handled.push((node, parent))

		while handled not empty:
			(node, parent) = handled.pop()
			split_node(node, parent)


- enter handle_node
- subnodes pull request
- subnodes handled
- enter split_node
- subnodes push request
- node handled

== Functionality ==

TODO sort this out

FetchTokenEntries [term]
ClearTokenEntries [term]

InsertTermEntry [data]
RemoveTermEntry [data]

FetchURIEntry [uri]
ClearURIEntry [uri]

InsertURIEntry [data]
RemoveURIEntry [data]

PullIndex [index]
PushIndex [index]






== Data elements ==

A "term" is a discrete phrase that results are associated with. This is just a
Java String, and can contain any character including whitespace.

A TermEntry stores data about a particular result for a term. Each entry has a
subject term and a relevance rating in [0,1]. Further types are:

 : TermTermEntry - redirects to another search term
 : TermIndexEntry - redirects to another index
 : TermPageEntry - final target for term

A URIKey is the node routing-key part of a FreenetURI and is used as the key
into the URI table. FreenetURIs from the same "site" will have the same URIKey
and will be stored close together in the table. (TODO: this might not be
necessary, especially if we use B+-trees instead of B-trees.)

A URIEntry stores data about a particular FreenetURI. Each entry has a quality
rating in [0,1]. Further types are:
 : etc? TODO

=== Unimplemented features ===

At the time of writing, there is no support for terms containing whitespace in
either XMLSpider or the syntax of the queries in the end-user interface.

There is also no support for URIEntrys in the spider or the interface.

== Data structure ==

 |-- contains
 :   subclass of

Index
 |-- metadata
 |-- ttab: BTreeMap<String, BTreeSet<TermEntry>>
 |-- utab: BTreeMap<URIKey, BTreeMap<FreenetURI, URIEntry>>

The index root would usually be stored as an SSK splitfile.

Conceptually, the ttab (term table) structure maps a term to (the collection of
entries for that term), and the utab (URI table) maps a FreenetURI to a single
unique URIEntry.

Structurally, both the ttab and utab are doubly-nested B-trees. There is a top
level B-tree, which maps a key to a further B-tree, which in turn holds data.

For the ttab, the top level B-tree maps a term to its entries collection, which
is a B-tree and can be nagivated. For the utab, the top level B-tree maps a
URIKey to a lower level B-tree that maps a FreenetURI to its URIEntry.


DOCUMENT usage of Bins


== Filters ==

TODO implement filters, think about how to do this...


